<8.10>

SpinLock 

싱글코어에서 스핀락은 아무 의미 X

스핀락은 타임슬라이스 안에 획득이 가능하면 가장좋음
SpinLock은 CPU를 100%점유

SpinLock은 개념적으로 Lock이지만, 스레드를 block X

--------------------------------------------------------------------------

SpinLock과 컨텍스트 스위칭

SpinLock역시 타임슬라이스를 모두 소모하면 컨텍스트 스위칭 일어남
타임슬라이스가 20m/s인데 SpinLock 걸려는 시점이이 19m/s일 수있음

타임슬라이스 내에 진입하기를 희망하는 것일뿐, 보장받지는 못한다.

--------------------------------------------------------------------------

yeildProcesser()

요즘 스핀락에는 하이퍼스레딩이 지원되는 환경에서 일드프로세서를 통해,
한번씩 다른 스레드에게 돌 수있는 기회를 제공

이는 컨텍스트 스위칭이 아니며 OS입장에서는 코어가 자기할일을 하는걸로인식.

--------------------------------------------------------------------------

동기화 객체

동기화객체는 1m/s안에 임계영역을 얻을 수있다고 하더라도 그 즉시 block.
(단, 요즘 유저동기화 객체는 일정회수 SpinLock을 돌려보고 block.)

--------------------------------------------------------------------------

Sleep(0)

Sleep(0)의 경우 스케쥴링 되어 내 ReadyQ의 가장 뒤쪽에 큐잉된다.
동기화객체는 Block -> Ready -> Running되기 때문에 sleep(0)보다 느리다.

--------------------------------------------------------------------------

커널모드 전환 유무

예전기준 동기화객체를 사용했고, 독점접근이 가능할때 (경합발생 X)  (X)
(인터락 비트체크를 하고 빠짐)

요즘 유저모드동기화 객체는 완벽한 유저모드로 돌아간다. (X)

커널모드 객체일 경우 (0)

--------------------------------------------------------------------------

피터슨 알고리즘

인터락 함수를 쓰지않고 단순히 flag체크하여 두개의 공간을 두고,
두개의 스레드가 서로 안전하게 진입하는 것을 목표로 삼은 알고리즘.

--------------------------------------------------------------------------

피터슨 알고리즘을 우리가 쓰지못하는 이유

우리 동기화객체는 어떤 스레드든 독점적인 접근이 되도록 하는것으로,
스레드 두개마을 넣고 바꿔가며 돌아가는 것이 아니다.

--------------------------------------------------------------------------

SpinLock의 구현

변수를 하나두고, InterlockedExchange()를 사용해 진입여부 판단
yeildProcesser 명령어로 한번씩 다른스레드에게 기회 줄 수 있음..

일반 if문을 사용해 인터락의 호출회수를 줄이는것도 가능함.

--------------------------------------------------------------------------

SpinLock이 실제로 사용되는 부분

OS커널 내부같이 실행의 요소가 단시간으로 만들어진 경우 사용.
최근 유저동기화 객체들이 내부에서 사용.

--------------------------------------------------------------------------

SpinLock을 직접구현하여 쓰지않는 이유

직접구현하여 컨텐츠에서 사용한다면 역효과가 날 가능성이 너무 큼.
(타임슬라이스를 넘어 block되어버리는 경우 걱정)

결론적으로, SpinLock이 필요한경우 유저동기화객체에 내장된 것을 사용한다.

--------------------------------------------------------------------------

Lock-Free 알고리즘


Lock-Free는 내부적으로 락을 걸지않는다. (busy wating이라는 표현도 존재)
락프리는 진입과정에서 검사하지않고, 일단 진입한다.

SpinLock - 접근을 목적으로 루프
LockFree - Commit에 대한 루프

--------------------------------------------------------------------------

Lock-Free의 포트폴리오 적용

검증차원으로 IOCP모델에 적용하며, 모든 문제상황의 시나리오 설명을 요함

--------------------------------------------------------------------------

사전작업과 최종확인 작업

예시코드에서는 do while로 들어간다.

사전작업은 자료구조에 변화를 두지않고, 나혼자 진행하는 작업을 뜻함.
최종확인 작업은 반영하고자 하는 자료구조에 한번 반영하는 것을 뜻함.

--------------------------------------------------------------------------

락프리 자료구조 모델

포인터를 교체하는 한번의 행위로 Commit이 되야하므로 list로만 구현가능
Lock-Free Stack에서는 Top에대한 변화유무에 따라 재시도/PUSH가 결정날 것.

--------------------------------------------------------------------------

실무에서 락프리 적용

동기화객체를 사용한다면 문제해결이 간단하고, 
이렇게 까지 성능을 신경쓰지 않기때문에 대부분은 동기화를 걸고 안전하게 감.

더군다나 락프리는 NC/Nexon같은 곳에서도 검증이 어려워 사용하지않음.

--------------------------------------------------------------------------

CAS(Compare and Swap)

비교와 교체까지 atomic하게 해주는 것을 뜻함.
윈도우 환경에서 CAS는 InterlockedCompareExchange()가 된다.

--------------------------------------------------------------------------

더블 CAS

동떨어진 변수 두개를 CAS하는것은 불가능하다.
변수 두개를 합쳐(이어지는 메모리) CAS하는것은 가능.

InterlockedCompareExchange128을 이용해, 64비트 변수 두개를 CAS가능.

이같은 기능이 CPU차원에서 보장되지않는다면 LockFree는 구현불가능.

--------------------------------------------------------------------------

주소 경계에 세우기

인터락함수는 무조건 본인데이터에 맞는 경계에 서야한다.

일반적인 Interlocked함수들은 경계가 맞지않는 경우 단순히 atomic연산실패
Interlocked128같은 경우는 내부에서 Crash가 난다.

더블CAS를 사용할 TopNODE는 그냥 선언하면 8바이트경계에 서게되므로, 
16바이트 경계에 명시적으로 맞춰줘야한다.

--------------------------------------------------------------------------

개발자가 명시적으로 경계를 잡는 경우

컴파일러는 시작점이 0이라는 전제로 가기때문에, 인위적으로 패딩을
건드리지 않는이상 변수들은 자기경계를 찾아간다.


경계를 명시적으로 잡기위해서는 표준으로 정의한

alignas(n) / _aligned_malloc(n)을 사용해야 한다.
alignof(자료형) 으로 어느 경계에 서있는지 얻을 수있음.

--------------------------------------------------------------------------

InterlockedExchange() 사용법

Dest 목표로 하는 데이터
Exc  바꿀 데이터
Comp 비교대상 데이터

반환값

실패/성공 여부 상관없이 원본값 반환

--------------------------------------------------------------------------


InterlockedCompareExchange128() 사용법

Dest    목표로하는 데이터(128비트)
ExcH    상위 부분과 교환할 64비트 데이터 (주소값이 큰 데이터)
ExcL	하위 부분과 교환할 64비트 데이터 (주소값이 작은 데이터)
CompRes 대상과 비교할 64비트 정수(128비트로 간주) 포인터.
성공여부와 관계없이 이쪽으로 이전값을 뱉어준다.

반환값 - CAS성공했다면 1, 실패했다면 0.

Dest값은 무조건 16바이트 경계에 서야한다.
우리가 선언할 수있는 변수의 최대크기는 8바이트이므로, 8바이트 경계에섬.

--------------------------------------------------------------------------

락프리 - 단일리스트 구현

자료구조에 영향을 주는 작업은 단한번의 commit으로 끝나야한다.
싱글리스트의 경우 사전작업이 자료구조에 영향을 주지않으므로 구현가능

--------------------------------------------------------------------------

락프리- 더블리스트 구현

기존 Top노드 저장
새노드생성, 새노드Next에 TopNode연결

CAS (저장한 Top이 현재 Top과 같으면 NewNode를 새Top으로 지정)

이때 더블리스트의 경우, NewNode->Next->Prev가 NewNode를 가리켜야한다.
이는 CAS에 더해 한가지의 작업을 더 필요로 하고, 구현불가.

--------------------------------------------------------------------------

락프리 - 배열형태 구현

배열은 저장공간이 정해져있고, rear가 pop이 Index를 가리킨다.

1. 데이터 push
2. Index증감/차감

이 두가지행위를 한번에 commit하지못하므로 구현 불가능

--------------------------------------------------------------------------

LockFreeStack의 push 구현


.........................................

1. 기존 Top백업
2. 새노드에 next로, 백업Top 연결

......................................... 

3-1. 백업Top노드와 기존Top노드 비교
3-2. 비교결과가 같다면, 새노드를 Top으로 Commit
3-3. 비교결과가 다르다면, 다시 1번으로.

.........................................

1,2는 자료구조가 전혀 모르게 진행되고,
3은 CAS를 사용해 atomic하게 한방에 진행

--------------------------------------------------------------------------

동시에 치고들어오는 경우, 순서보장

순서는 어떤것도 보장받을 수 없으며, 이를 문제삼지 않는다.

--------------------------------------------------------------------------

LockFree에서 경합이슈

일반적인 스택을 기반으로 구현한다면 경합이 많이 발생하지 않음.

우리가 적용할 것은 락프리스택(Index스택), 락프리큐(SendQ), 락프리메모리풀
을 사용하고 이때 코어개수 이상으로 스레드를 만들어 push/pop하면
루프가 1,20만번까지도 돌 수 있음.

어쩔수없는 상황이다.

--------------------------------------------------------------------------

ABA문제

모든 락프리자료구조에서 ABA문제가 나타난다.
(CAS는 절대 오작동하지않음)


stack push의 경우는 Top체크만으로 Commit여부 결정가능 (문제없음)
stack pop의 경우는 Top체크만으로 Commit여부 결정불가(ABA문제때문)

--------------------------------------------------------------------------

ABA문제 해결

1. 포인터를 유니크하게 사용

포인터 메모리의 일부구간 비트를 다른 용도로 사용한다.

32비트 환경에서는 실패할 가능성이 높을 것이고,
64비트라고 하더라도 100%안전한 것이 아니기 때문에 권장 X

..........................................................................

2. Top과 Top->pNext를 더블CAS로 간다.

Top과 Top->pNext가 동일하다면 자료구조 변화유무와 관계없이 성공.


..........................................................................

3. 별도의 Count를 두고 더블 CAS를 진행 (권장)


Top->Next의 변화유무가 아닌 자료구조 자체의 변화유무를 판단하는 방법

top주소를 저장하는 포인터를 128비트로 만듬
64비트 자료형 두고, 자료구조가 바뀔때마다 변경시킴.

비교시 노드+자료형을 포함한 더블CAS로 비교함

..........................................................................

UniqueCount를 두는 방법의 단점

ABA문제는 UniqueCount로 자료구조 변화유무를 판단하는 방법이 주로사용됨

이 방식은 ABA문제가 아닌 경우에도 변화가 감지되면 CAS에 성공하지못한다.

push는 Top의 next가 달라졌다고 하더라도 문제될게 없으므로,
굳이 더블CAS를 사용할 필요는 없음.

--------------------------------------------------------------------------

노드생성 방식

락프리를 만드는이유는 락을 걸지않고, CPU를 더 사용하여 좀더 빠른처리를 
기대하기 때문이다.

new/delete는 thread-safe하게 만들어졌기 때문에 내부에서 동기화 진행.
처음에는 new/delete로 진행하지만 메모리풀로 최종변경 할 것.

--------------------------------------------------------------------------

LockFree 에러 상황

락프리스택에 push/pop을 반복하여 스택의 크기를 확인하고, 
데이터 역시 검증한다.

1. 메모리 참조 오류
ABA문제 발생 후 메모리 참조 오류, 잘못된 delete시도.

2. 내가 A노드를 pop했는데 다른쪽에서 또 pop해가는 문제
3. 데이터 유실 (push했는데 사라진 상황)


2,3번의 경우는 우리가 직접 테스트해야 하는 부분이다.

--------------------------------------------------------------------------

Lock-Free테스트

[스래드 개수 * 데이터 개수]를 큐에 push/pop하며 테스트

struct DATA
{
	LONG64 Data;
	LONG64 Count;
}

1. 데이터 준비(동적 할당), 초기화
2. 자료구조에 push

3. 약간대기 (다른스레드에서 뽑아가도록 유도)

4. 내가 넣은만큼 pop 
5. 데이터 값 확인
6. 뽑은 데이터 값 변경 (인터락 +1 씩)

7. 약간 대기

8. 변경한 데이터가 그대로인지 확인 (누군가 사용하지는 않는가?)
9. 데이터 초기화 (인터락 -1씩)
10.변경한 데이터가 그대로인지 확인 
11.데이터삭제

반복

--------------------------------------------------------------------------

delete 유무

delete유무는 선택사항이다.
delete를 추가하면 메모리 참조오류, 댕글링포인터 삭제 오류등이 유도

--------------------------------------------------------------------------

테스트환경 

스레드는 논리 스레드 개수에 딱 맞추는게 가장 테스트가 잘된다.

다수의 스레드를 사용하는 경우 실행되지못하고 ReadyQ에서 기다림.
코어가 높을수록 문제가 더 잘나올 것.

--------------------------------------------------------------------------
--------------------------------------------------------------------------
락프리스택 문제 - malloc / free

인터락을 보장받기위해 경계에 맞춰야 하므로,
alignas로 구조체를 선언하여 할당하거나,
_aligne_malloc()을 이용하여 할당한다.

이때 문제는,

--------------------------------------------------------------------------

1. malloc / free자체의 느린 성능
2. malloc / free의 자체 내부 동기화
3. CAS시 메모리 참조 오류가 나는 상황

--------------------------------------------------------------------------

메모리 참조 오류가 나는 구조적인 문제

pop()에서는 TopNode를 백업시켜 로컬변수인 tNode를 기준으로 로직 진행

	TopNODE* tNode = this->TopNode;

이때 CAS를 하려고 할때, 어디선가 pop하여 해당 노드가 delete된다면?

이는 유효하지않고, 이 경우 tNode->NextNode를 접근하려고 하는 경우
메모리 참조 오류가 나게된다.

--------------------------------------------------------------------------

위와같이 메모리 참조 오류가 나지않는 경우

Page-fault되지않아 문제가 나지않을 수도있다.
하지만 언제 Page-fault될지 알 수없으므로 이에 의존적인 로직은 X

delete를 사용하는 경우 0x08123으로 초기화되기 때문에 100%메모리 참조오류

--------------------------------------------------------------------------

LockFree-FreeList(메모리풀) 도입

위와같은 문제를 피하기위해 락프리 메모리풀을 사용한다.
하지만 락프리 메모리풀 역시 스택과 거의 유사한 구조이므로,

스택이 가진 구조적인문제(3)를 가지고 있다.

--------------------------------------------------------------------------

노드의 생성 / 삭제 문제

이 구조적인 문제는 락프리스택이 내부에서 delete하기 때문에 생긴다.
즉, 매번 생성/삭제하는 구조때문에 메모리 참조오류를 피할수 없음.

--------------------------------------------------------------------------

락프리 스택 vs 락프리 메모리풀

LockFree자료구조 - 데이터(<T>타입) 자체를 사용자에게 전달/회수
따라서 이를 담아 관리할 노드가 필요하므로, 필연적으로 매번 생성/삭제 발생


LockFree메모리풀 - 노드자체(NODE*)를 전달/회수
노드를 본인이 만들고 사용자에게 대여/회수 하기때문에 생성/삭제 필요 X


따라서 락프리 메모리풀은 매번 생성/삭제할 필요가없으므로,
락프리구조의 독립적인 구현이 가능해진다.

--------------------------------------------------------------------------

내부에 데이터가 없는데 pop하는 경우

데이터가 없는 경우 pNode의 pNext를 찌르는쪽에서 메모리 참조 오류가 난다.
실제 상황에서는 별도의 예외처리 코드로 막아야 하지만,

우리가 진행하는 테스트 환경에서는 있을 수 없는 일이므로
일부러 메모리 참조 오류가 나게끔 한다.

--------------------------------------------------------------------------

메모리풀 락프리 스택 테스트

락프리 메모리풀역시 스택과 같은 형태로 테스트가 진행된다.
일단 스레드 CPU개수에 맞춰 Sleep()없이 돌린다.

이때 다른스레드에서 데이터를 뽑아 값을 변경하게끔 하기위해 Sleep(1)
을 넣기도한다.

--------------------------------------------------------------------------

락프리 Empty()체크

1. Top->Node가 nullptr인지 체크
2. 내부에 할당된 StackSize로 파악

메모리풀에서는 (AllocCount - UseCount == 0)으로 했지만,
락프리의 경우는 문제가 난다.

어떻게 해결해야할지 고민해봐야 할 것.

--------------------------------------------------------------------------

락프리 ABA문제

락프리 스택 push에서는 ABA문제가 나지않음.
(왜 문제가 나지않는지 정확히 숙지)

락프리스택의 ABA문제는 pop에서 하나 존재함.
큐는 여러개의 ABA문제를 가짐

--------------------------------------------------------------------------

락프리 큐 구현시 문제

Front와 rear가 동시에 null을 가리키면,
head/tail모두 null인경우 head/tail을 동시에 NewNode로 바꿔야함.

따라서 front나 rear둘중 하나만 건드리는데 다른쪽까지 변경이 되어야함.
이 경우 락프리 구현불가.

--------------------------------------------------------------------------

락프리 큐 구조

1. head / tail이 포인터로 존재


head = nullptr;
tail = nullptr;

[Enqueue]

head = Node1;
tail = Node1;

[Dequeue]

head = nullptr;
tail = nullptr;


이는 head를 변경하면 tail까지 바뀌어야하므로 락프리구현불가.

.........................................................................

2. head/tail이 실제 노드로 존재하는 경우


head = headNode;
tail = tailNode;

[Enqueue]

headNode -> Node1 -> tailNode;

Deuque시 head->next를 삭제하고, 
head->next->next(tail)을 head->next를 연결해주면 끝

따라서 더미를 사용한다면 nullptr인지 체크할 필요가 없으므로, 간단해짐.

--------------------------------------------------------------------------

head/tail이 노드로 존재할 경우 시뮬레이션

..........................................................................

2-1. Dequeue

head -> Node1 -> Node2 -> tail

[Dequeue] 하려면?
1. head->Next = Node2;

head->Next->Next가 변할 수있으나 DCAS로 진행되면 문제없음.

-> Dequeue는 문제없다.
..........................................................................


2-2. Enqueue

head -> Node1 -> rear;

[Enqueue : Node2] 하려면?

1. Node2->Next = rear; 
2. Node1->Next = Node2;     --> Node1을 알수 없음 

결론 : Node1을 알 방법이 없으므로 구현불가
(더블리스트 형태면 가능하지만, 더블리스트는 락프리구조에서 구현불가)


만약 rear가 포인터 형태라면 rear가 Node1를 가리키고있을 것이고,
Node1->next = Node2; 로 구현이 가능.

--------------------------------------------------------------------------

락프리 큐 구조 개선

1. 더미없는 구조는 head, tail을 동시에 건드려야 하므로 구현불가.
2. head,tail 둘다 노드가 있는 구조는,
   Enqueue는 문제없지만
   Dequeue시 이전노드에 접근할 방법이 없으므로 구현불가.


따라서 front는 더미가있지만 rear는 포인터로 존재하게 구현한다.

.........................................................................

개선1 구조의 문제


head*             tail*

  ↓                ↓

Dummy     ->     nullptr


[Enqueue : Node1]

head->Next = Node1;
tail = Node1;

다시 front와 rear둘다 건드리는 처음의 문제로 되돌아감.

Dequeue문제는 해결됐음.
Enqueue가 다시 문제가 나게됨


--------------------------------------------------------------------------

락프리 큐 최종구조

1. head는 포인터 형태로 존재
2. head는 Dummy를 가리키고, 생성자에서 Dummy생성
3. Dummy데이터 뒤에 실제 데이터 노드가 이어짐
4. tail역시 포인터 형태
5. 더미는 고정이아니라, 마지막에 썼던 노드를 다시 더미로 활용

.........................................................................

자료구조 형태

head*                            tail*

↓                                 ↓

Node1(Dummy) -> Node2 -> Node3 -> Node4

(Node1은 이미 Deque되었지만 자료구조 내부에선 더미로 사용중)

.........................................................................

최초 생성시 자료구조

head*           tail*
      ↘       ↙
          tmp

Dummy가 필요하므로 tmp노드 동적생성.

.........................................................................

[Enqueue : Node1]

1. tmp->pNext = Node1;
2. tail = Node1;


  head*           tail*

  ↓               ↓             

  tmp      ->     Node1

.........................................................................

[Dequeue : Node1]

1. tmp->Next return
2. head = tail(Dummy);
3. delete tmp


head*           tail*

      ↘       ↙

      Node1(Dummy)

.........................................................................


1. Enqueue또는 Dequeue시 head, tail을 동시에 건드려야하는 문제 해결
2. 특정 노드를 찾아갈수 없는 문제 해결
3. head, tail 어떤것도 nullptr을 가리키지 않음.

--------------------------------------------------------------------------

락프리 큐 Dequeue

head->pNext의 데이터를 리턴, Dummy를 삭제.
데이터를 담아놓고 자료구조 변경이 없었다면 

1. head = head->pNext.(더미가 될 노드이자 리턴할 데이터를 가진노드)
2. 이전 head(더미) 삭제

문제없음

--------------------------------------------------------------------------

락프리 큐 Enqueue 구조 문제점

락프리스택에서는 NewNode가 Next로 Top을 가리키는것이,
자료구조에 아무영향 X.

하지만 락프리 큐는

1. tail->pNext = NewNode;
2. tail = tail->pNext;

위 둘중 어떤 행위를 먼저하든 자료구조가 변경되고, 둘을 DCAS하는것은 불가

--------------------------------------------------------------------------

락프리 큐 Enqueue 개선

1. 새노드를 tail->pNext를 연결시키는 행동
2. tail이 새노드를 가리키도록 변경

이 두단계를 한번에 Commit하는것이 불가능하므로, 두단계로 나눠 처리.

--------------------------------------------------------------------------

1. 새노드를 tail->pNext를 연결시키는 행동

CAS를 통해 tail->pNext == null인 경우 tail->pNext = NewNode;
위 구문이 성공했다면 Enqueue성공으로 가정한다.

이때, tail->pNext는 언제든 pop될 수있는 상황이고, pop된경우
tail이 nullptr이 되기때문에 nullptr메모리 참조오류가 나게됨.

(위 작업은 Dequeue는 head를 타고 next로 오는것이므로 문제없을 것.)

.........................................................................

Stack(pop)에서 비슷한 문제

CAS시 TopNode->pNext를 사용해야함. 언제든 다른곳에서 pop될수있는 상황이고, pop되어 TopNode가 nullptr가되면 메모리참조오류.

이 상황을 락프리 메모리풀을 사용함으로서 해결.

.........................................................................

1-1. 새노드를 tail->pNext를 연결시키는 행동의 문제

락프리 큐의 경우는 해제도 역시 문제고,

비교 조건이 if(tail->pNext == nullptr)이기 때문에 엉뚱한메모리에 
추가될 가능성도 있음.

따라서 큐역시 메모리풀을 사용해야만 구현이 가능하다.

--------------------------------------------------------------------------

1-2. 새노드를 tail->pNext를 연결시키는 로직

1. Tail노드 백업.
2. 백업노드->pNext( = tail->pNext) 백업
3. CAS전 예외처리(백업노드->pNext == nullptr)
4. 맞다면 Enqueue(CAS) 시도

이때 별도의 예외처리를 사용해 CAS호출을 줄일 수있다.
(다른쪽에서 tail을 바꿔 pNexttail이 null이 아니면 어차피 CAS실패)

--------------------------------------------------------------------------

2. tail이 새노드를 가리키도록 변경하는 행동

앞서 tail->next == nullptr인 경우 새노드를 추가해 Enqueue의 절반을 수행함.
그다음 할일은 tail이 새노드를 가리키도록 변경하는 것.


따라서 CAS가 두번이 들어가는데, 첫번째 CAS가 성공하면 Enqueue성공으로 간주

첫번째 CAS가 실패하는 경우 Enqueue실패로 다시 돌아간다.
두번째 CAS는 실패여부를 판단하지않고 그대로 빠져나온다.
(tail을 밀지못했더라도 빠짐)

--------------------------------------------------------------------------

2-1. tail 변경 실패

head*            tail*

  ↓               ↓      
     
Dummy      ->    Node1       (+ NewNode) 추가할 예정


head->next = NewNode        (1) (새로운 노드 삽입)
tail = tail->pNext(NewNode) (2) (rear이동)

결국 (2)는, CAS(tail, NewNode, Node1)와 같은 형태로 tail을 바꾸게 될것이다.
                  ↑      ↑     ↑
		(Dst)   (Exch) (Comp)


tail이 실패하는 경우는 tail != 새노드.
누군가가 tail을 추가한 상황이다.

왜 이런상황이 나올까?
	
....
락프리 잠시중단.

--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------
--------------------------------------------------------------------------

락프리 vs 동기화

락프리스택/큐는 동기화객체를 사용하는 큐/스레드와 비교되어야할 것.
만약 완성한다면 성능을 Test해볼 것.

우리가 만든 락프리가 더 느리다고 하더라도, 우리는 락프리를 사용할 것.

--------------------------------------------------------------------------

Interlocked vs SRWLock

성능은 당연히 인터락이 빠르다.
유저 동기화객체 내부에서 기본적으로 인터락을 활용.

비교대상이 유저동기화 객체가 아닌 커널 동기화 객체인 경우,
성능차이는 매우 심할 것이다.

--------------------------------------------------------------------------


SRWLockExclusive();

Data++;  
Data++;                                                      
Data++;
Data++;

SRWLockRelease();
...........................................................................

vs

...........................................................................

InterlockedIncrement((long*)&Data);
InterlockedIncrement((long*)&Data);
InterlockedIncrement((long*)&Data);
InterlockedIncrement((long*)&Data);


이경우 SRWLock의 경우 캐시히트율이 100%이므로, 대부분의 상황에서 더빠름.

위와같은 상황인 경우 SpinLock과정에서 타임슬라이스 내에 연산이 끝날 것.

인터락 역시 경합이 발생되면 성능이 하락된다.
인터락이 많아질수록 성능저하는 더욱 크게 일어난다.


Interlocked < InterlockedExchange < CompareExchange < CompareExchange128

순으로 성능이 떨어진다.


--------------------------------------------------------------------------

인터락 캐시히트 문제

인터락은 해당값을 원자적으로 바꿔주는 작업.
CacheHit는 캐시 메모리만을 바라보고 작업하므로 성능향상을 기대.

이때 인터락은 인자로 들어온 변수에 접근하는 모든 메모리를 차단.
CPU차원에서 해당 메모리 번지를 대상으로 값을 조회하려는 CPU차단.

따라서 이 행동자체가 값을 대상으로 모든 코어의 캐시히트율을 없애버리는 것.

인터락이라는 행동자체가 값을 변경시키는 것으로, 다른코어에 있던 
캐시들은 무효화 된다.


--------------------------------------------------------------------------

캐시히트 관점에서 보는 SRWLock vs 인터락

위 예제를 다시보면, 다른코어에 올라간 메모리는 모두 캐시무효화가 되지만
내코어에서 캐시히트는 100%보장된다.

이에반해 인터락 같은 경우 레지스터값을 올려놓고 ++하는 행위와 다름.

인터락 관련 함수들은 해당 포인터를 꽂아넣고 [xadd 1]을 진행하는 것으로,
해당 메모리를 잠궈버리고 1을 증가 시키는 것이다.

--------------------------------------------------------------------------

LanServer에서의 인터락 vs 동기화 객체


경합이 빈번하지않다면 동기화객체/인터락의 성능차이는 크지않음.


네트워크 라이브러리내부에서는 경합이 거의 발생하지않음

워커스레드는 몇 안되는것에 비해, 세션은 5천개 이상이 들어감
여러 스레드가 하나의 세션을 대상으로 깨어날 가능성 X

따라서 어떤것을 쓰더라도 큰 차이 X

--------------------------------------------------------------------------

LanServer에서 동기화이슈가 날만한 부분

 - Send안료통지 / Recv완료통지가 같이 오는 것.

 - 완료통지 / 컨텐츠쪽에서 어떤행동을 요청하는 것.


이둘은 거의 가능성이 없음.

--------------------------------------------------------------------------

어플리케이션 입장에서의 성능


프로그램 환경에따라, 경합발생 블락되고 다른스레드를 돌리는것이 좋을수있음

내가 할일을 CPU점유율을 계속사용하여 루프돌리면 10m/s가 걸리고,
동기화가 걸리는 경우 20m/s가 걸렸다고 가정한다.

해당 스레드입장에서만 이득일뿐, 프로세스 전체로봤을때는 어떨지 알수없다.

--------------------------------------------------------------------------

LanServer에 적용한 동기화이슈 해결책

IOCount는 Overlapped I/O가 잘못되는 상황을 막기위해 사용.

Lock의 경우 Session을 사용중일 때 지워지는 것을 막기위해 사용(이중락)
(이제 배열로 가기때문에 지워질일은 없음)

--------------------------------------------------------------------------

기존 세션락 삭제 시 문제

락을 피하기위해 배열을 사용 -> 생성/삭제 로직시 락 필요 X
락이 없어진다면 동기화 이슈는?

WorkerThread내부에서는 Session을 사용할때 IOCount를 물고있으므로 삭제X

하지만 바깥에서 접근해오는것은 허용해줌 -> 얼마든지 접근이 가능
내부에서 Release를 진행하고있는데, 바깥요청으로 인해 Release접근가능

--------------------------------------------------------------------------

세션에 대한 동시접근 문제

1. RecvQ링버퍼

    Recv완료통지에 대해 하나의 Overlapped구조체만을 사용함


2. SendQ링버퍼
  
    락프리 큐를 사용하여 해결


3. Release되는 경우

    문제있음(곧이어 언급)

--------------------------------------------------------------------------

락을 없애고 가려는 이유

Lock을 건다면 나 이외에는 아무곳에서도 접근이 불가능.
누구든 접근하여 일을 하게끔 의도하는 것.

따라서 락을 없앴다고 하더라도 한쪽에서만 접근이 가능하다면 의미없는 행위

--------------------------------------------------------------------------

Session에 접근하는 경우

..........................................................................

컨텐츠쪽의 접근

SendPacket(send요청)
Disconnect(Session끊기 요청)


SendPacket - 락프리큐를 사용하므로 동시접근 문제 X
Disconnect - 동시접근 문제 O

..........................................................................

라이브러리 내부에서의 접근

WorkerThread() GQCS완료통지 부분에서 접근

--------------------------------------------------------------------------

구체적인 상황

1. 바깥에서 접근한 Session이 이미 Release된 경우

    보낼대상이 사라진 것이므로 상관 X
    SessionID는 유니크한 값이므로, Find되지않고 false리턴됨.


2. 바깥에서 접근한 Session이 재할당되어 다른 Session이 되었다면?

    SessionID는 유니크하므로 Find되지않고 false리턴.
    하지만 검색이후 SendPacket 도중 해제-재할당 되다면 외부에서 알수없음

    SendPacket도중에 종료요청이 와서 IOCount() == 0 으로인해 해제
    이후 Accept로 세션 재할당.

--------------------------------------------------------------------------

Session 재할당 문제에 대한 해결


Session에 대해 접근하여 사용할때, Release를 막아버린다면 근본적으로 해결.

1. Disconnect()요청 -> 이미 Release진행됐거나 진행중이라면 빠져야함

2. SendPacket() ->  Send이후 Release해야할 상황이라면, 못하게해야함.


1의 경우 단순히 진행하던 Release()구문에서 빠지면된다.
2의 경우 Release해야할 상황을 막았으므로, 내쪽에서 Release해주야 한다.

--------------------------------------------------------------------------

해결 포인트

누구든 접근이 가능하여 사용이 가능하지만,
한쪽에서 접근을 하는동안 다른쪽에서 Release하는것을 막으면 해결됨

--------------------------------------------------------------------------

IOCount기능의 확장

I/O작업의 누적치를 Count하는 용도로 사용했음.
이제부터는 기능을 확장하여 참조카운트 기능을 겸하도록 한다.

--------------------------------------------------------------------------

Disconnect()시 동시접근 

Disconnect에서 접근한다고 가정.
Disconnect의 역할은 Session의 연결을 끊고, Release되도록 유도하는 것.
(Disconnect는 외부에서 끊기를 요청할 때 사용하므로 아직까지 사용X)


1. Session을 사용하기위해 Release막음   -> IOCount증가
2. 1번로직 이전에 재할당된 경우         -> SessionID확인
3. 해당 Session에 대해 작업을 수행      -> Session작업 수행 (Send/Discon)
4. 막았던 Release를 할수있게끔 풀어줌   -> IOCount 감소

5. 다른곳에서 IOCount로 인해 Release로직을 타지못했을수있음.
   -> 따라서 if(IOCount-- == 0)인경우 Release 호출

--------------------------------------------------------------------------

위 방안에 대한 문제 - Release중복

사용하기위해 IOCount증가.
그런데 이미 Release가 될 Session이거나, IOCount가 0이라면?

[0 -> 1 -> 0]이 되어 Release가 두번 될수있는 상황임
(0이되어 Release구문에 들어가려는데, 이쪽에서 다시 증가-감소)

--------------------------------------------------------------------------

Release문제를 막기위한 해결방안

IOCount가 0이라는 것은 무조건 Release를 타게 된다는 뜻.

..........................................................................

IOCount++가 1인경우 Release하지않고 리턴.


A스레드에서 1인것을 확인하고 나가려는 찰나에, 
B스레드에서 접근하여 ++하는 경우 2가됨.

이경우 B스레드에서는 나가지못하고 이미 Release를타게됨. -> 중복Release

..........................................................................

차단하는 방식으로 해결불가 -> 서로 양보하는 구조


Release구문을 진입했는데 누군가 Sesson을 사용한다면 양보.
Session에 접근하여 사용하려고했는데 Release될 Session이라면 포기.

상당히 지저분해보이는 방식이다.
보통 세션관리자는 배열로 동기화없이 진행하고, 세션마다 락을 두는것이
가장 일반적이고 깔끔한 방식.

--------------------------------------------------------------------------

Cancel I/O

Cancel I/O는 걸려있는 비동기 작업만을 취소하는 것으로,
동기화 작업과는 관계없음.
동기는 이미 리턴하는 순간 완료된다.

--------------------------------------------------------------------------

완료통지가 오지않는 경우

WSASend가 호출될때, WSASend가 IOPENDING이 아닌 실패라면 완료통지 X.


--------------------------------------------------------------------------

TLS(Thread Local Storage)

동적TLS -> API차원에서의 기능 (이미 만들어져있음)
정적TLS -> 컴파일러 차원에서의 기능 (요청하면 만들어줌)

TLS는 OS차원에서 TLS기능을 제공해줘야 사용이 가능하다.
TLS는 모든 스레드에 달라붙으므로, 남발해서는 안됨.

--------------------------------------------------------------------------

TLS를 사용하는 CRL함수들

strtok  (그전까지 찾았던 포지션포인터를 내부TLS에 기억)
rand    (시드값을 TLS에 저장)

--------------------------------------------------------------------------

동적TLS

각 스레드마다 포인터배열이 정해져있다. (이미 만들어짐)
동적 TLS는 한계치가 존재(OS마다 다름). 한계치이상으로는 TLS할당 실패

실제로는 64개보다 훨씬 많이 존재..
런타임 라이브러리, DLL등 다양한곳에서 TLS활용하므로 부족할 수있음.
TLS공간에 포인터를 저장하고, 동적할당하여 사용하는것도 방법

--------------------------------------------------------------------------

정적TLS

정적 TLS는 요청하는만큼 용량이 늘어남

--------------------------------------------------------------------------

TLS의 필요성

지역변수로 TLS대체가 가능해 보일 수 있음.
이 경우 지역변수는 스레드가 호출될때마다 포인터를 전달해야함.

이러한 기능이 언제 어디서 사용될지 모르는 클래스형태 라이브러리 일경우,
지역변수 포인터를 전달하는 방식은 불가능.

--------------------------------------------------------------------------

TLS할당

TLS 할당은 프로세스 차원에서 관리
사용유무에 대한 비트플래그가 정해져있음

--------------------------------------------------------------------------

TlsAlloc() - TlsFree()

Index를 예약 / 해제
모든 스레드 뿐만아니라 나중에 생성될 스레드까지도 접근할 수있는 공간예약

보통은 생성자/소멸자에서 호출
Index는 당연히 여러스레드에서 접근가능한 곳에 저장

따로 할당실패를 알려주지않으므로, 반드시 코드에서 예외처리 해야함.
(할당 실패시 TLS_UT_OF_INDEXES 반환)

--------------------------------------------------------------------------

TLS 초기화

스레드가 생성 시 TLS는 해당스레드와 연계되는 수만큼 PVOID로 할당/0초기화

이를활용해 TLS를 활용하는 코드는 항상 최초호출 유무를 판단하여 
초기화하는 작업이 무조건 들어가야함.

TlsFree이후 TlsAlloc호출하여도 0으로 초기화된다.

--------------------------------------------------------------------------

TlsSetValue()

스레드가 가지고있는 배열에서 Index매개변수 값을 value를 전달하여 세팅
호출이 성공하면 TRUE를 반환

단, 다른스레드의 배열에는 절대 접근하면 안됨.


--------------------------------------------------------------------------

TLS 사용규칙 

힙은 프로세스 가동시 힙메모리 일정량을 commit.
그럼에도 우리는 malloc을 통해 힙메모리 할당받아 사용.

스택역시 다른스레드 스택을 포인터로 얻어다 사용가능.


문법적으로 가능함에도 굳이 이렇게 쓰지않는 이유는,
서로 규칙을 지키면서 안전하게 쓰기위함이다.

TLS도 마찬가지

--------------------------------------------------------------------------

TlsSetValue() / TlsGetValue 사용시 유의할 점

이 두함수는 성능을 위해 내부적으로 에러확인을 하지않음.
따라서 사용자가 엉뚱한 Index를 넣어도 내부에서 알려주지않음.

--------------------------------------------------------------------------

정적TLS

__declspec(thread) static int TlsValue = 0;

변수 하나를 TLS로 선언하면 끝난다. 
전역변수 또는 정적변수로만 선언이 가능하며, 모든스레드에 추가됨.
(이미 생성된 스레드, 생성될 스레드, 라이브러리에서 만들 모든 스레드)

--------------------------------------------------------------------------

정적TLS 내부구현

컴파일러가 컴파일 할 때 TLS라는 변수를 포함시켜 링커과정을 고치는 것.
운영체제가 반드시 개입해야한다.

--------------------------------------------------------------------------

정적TLS의 단점

컴파일러는 정적TLS변수를 참조하기위해 추가적인 코드생성.

이는 앱크기가 조금더 커지고, 속도는 조금더 느려진다.
(x86 CPU에서는 하나의 정적 TLS변수를 참조할때마다 세개의 기계어 추가)

--------------------------------------------------------------------------

동적TLS vs 정적TLS

정적 TLS는 추가코드 생성단점이 존재
동적 TLS는 함수 호출(TlsAlloc, TlsFree, TlsSetValue, TlsGetValue)

둘의 성능은 큰 차이가 없음.

개인적인 견해로는 만들어져있는것을 사용하는것이 좋다고 생각.

--------------------------------------------------------------------------

TLS적용 - 락프리 메모리풀

메모리풀을 아무리 락프리 스택으로 적용했다고 하더라도, 
동기화 객체를 쓰지않았을 뿐 성능이 향상된 것은 아님.

이제는 어떤 동기화작업, 스핀락, 락프리 없이도 동시에 Alloc한다면
Alloc되어야한다. 따라서 TLS를 적용하여 성능을 올린다.

--------------------------------------------------------------------------

TLS적용 - 프로파일러의 구현

Thread-Safe하게 모든 TagName을 기준으로 프로파일링되어야함.
따라서 스레드별로 저장하기위해 TLS를 사용

태그네임따라 취합하는 것도 좋음

--------------------------------------------------------------------------

프로파일러 출력

TLS로 저장한 프로파일러는 본인것밖에 출력이 불가능함
따라서 전역데이터에 보관해야함

--------------------------------------------------------------------------

TLS메모리풀 성능

결국에 여러스레드에 동시에 Alloc해야만 성능이 높아질 것.
하지만 동기화 이슈때문에 동기화/락프리/스핀락등이 들어감

--------------------------------------------------------------------------

스레드마다 메모리풀을 두기

그렇다면, 각자의 스레드가 각자의 메모리풀을 가지는 방법이 있음.
(메모리풀은 원래 종류별로 존재함. 각자란뜻은 스레드마다)

하지만 이 경우 A스레드에서 Alloc한것을 B스레드에서 Free하는경우 문제.

--------------------------------------------------------------------------

각기 다른스레드에서 할당/해제 시 문제


A스레드에서 할당하고 B스레드에서 해제한다면,
A스레드에서는 할당만 해오고 B스레드에서는 노드가 계속 쌓임

--------------------------------------------------------------------------

할당/해제하는 스레드가 달라지는 경우

현재 LanServer만 보더라도, LoginPacket은 AccepThread내부의 OnClientJoin()
에서 Join -> AcceptThread에서 Alloc하고 WorkerThread에 해제.

이외에도 빈번하게 나오는 상황으로,
오로지 스레드마다 각자의 메모리풀로 가는것은 불가능한 상황이다.

--------------------------------------------------------------------------

TLS메모리풀의 구조

스레드마다 미리 일정량의 Alloc하여 확보.
내 스레드에서 반환.

일정량 Alloc할때는 동기화가 걸리지만 스레드에 가져가서 사용할때는 
혼자만 쓰게되므로 여러스레드에서 동시에 Alloc가능.

--------------------------------------------------------------------------

위 형태의 단점

일정량(n)을 확보하여 낱개로 사용자에게 전달하므로,
사용자가 하나를 Free한다고 하여 메모리풀로 되돌릴 방법이 없음.

-> 메모리 낭비


따라서 Free라는 행동은 다썼다고 알려주는 형태로,
최종적으로 메모리풀로 데이터가 반환되는 시점은 n개가 모두 다쓰고 해제될때

--------------------------------------------------------------------------

TLS메모리풀의 청크 데이터

이때 n개의 데이터는 한번 Alloc시 재사용되지않음.

1000개를 할당받았고 1000개가 할당/해제되었다면, 
메모리풀로 반환하고 새로운 데이터1000개를 할당.

--------------------------------------------------------------------------

할당받아 사용하는 스레드입장

이때 할당받아 사용한 스레드 내부에서는 내가 할당한 n개의 데이터들이
어떻게 Free됐는지 알수없으며, 알 필요도 없음.

--------------------------------------------------------------------------

메모리풀의 입장

데이터가 어디서 쓰이는지 알아야하며, 마지막인자가 반환되면
메모리풀로 청크데이터를 반환하게끔 구현해야한다.

--------------------------------------------------------------------------

TLS메모리풀의 최종적인 형태

TLS는 내 스레드만 접근이 가능하므로, 이제 동기화의 걱정도 없음.

따라서 메모리풀을 포함하는 TLS메모리풀은 n개의 덩어리객체를 관리하는
메모리풀이 된다. (보통 청크라 부름)

--------------------------------------------------------------------------

TLS메모리풀(청크 메모리풀)

현재 Free된 데이터는 카운팅만 할뿐 재사용 하지않는다.
재사용은 각기 다른스레드에서 할당/해제 될 문제가 있기때문에 구현불가

어쨌든 하나를 ALLOC해도 청크크기만큼 사용하므로,
메모리낭비는 있을 수밖에 없음

--------------------------------------------------------------------------

청크크기와 성능

청크크기는 무조건 많이 잡을 수록 성능이 올라가는가?
실제로 비례하게 성능이 빨라지지않음.

어느정도 까지는 효과를 보지만, 그 이상은 영향이 없을 것이다.


--------------------------------------------------------------------------

청크크기에 비례하여 성능이 올라가지않는 이유


예상하건데, 메모리풀TLS로 얻을 수있는 성능은 동기화를 없앴기때문.

동기화르르 줄여 얻는 성능에 더해 청크크기가 크면 클수록 Alloc/Free호출이
적어지긴 하겠지만 일정크기 이상이되면 거의 동기화가 일어나지 않을 것.

--------------------------------------------------------------------------

메모리풀의 형태 

지금껏 만든 메모리풀은 락프리, 가변길이 등의 이유로 리스트로 만듬.

하지만 청크의 경우 메모리풀에 데이터를 할당/반납을 반복하는 것이 아니라
정해진 크기를 뽑고 반납하기 때문에 굳이 리스트로 갈 이유가 없다.

따라서 기존의 메모리풀을 그대로 활용하고, 이를 랩핑한 메모리풀TLS등장.

--------------------------------------------------------------------------

최종적인 TLS메모리풀 형태

사용자쪽에서는 일체의 수정없이 이름만바꾸면 되게끔 구현.
(메소드를 모두 같게 가자는 의미)

[스레드에서 Alloc요청 -> TLS메모리풀이 일정량 할당 -> 스레드에게 할당]

이 형태가 완성된다면 new/delete보다 8~10배이상 빠르게 나와야하는것이 
검증되어야 한다.

--------------------------------------------------------------------------

락프리큐 내부 메모리풀의 TLS화

동적TLS의 경우 개수제한이 있기 때문에 사용불가.
정적TLS의 경우 개수제한은 없을것이나, 메모리가 많이 사용됨.

TLS변수 자체가 전역변수가 되어야하므로 사용할 수없음.

가변크기의 메모리가 필요한데, 이를 전역변수로 사용할 수는없다.
	
--------------------------------------------------------------------------

Index감소방식 vs Index증가 방식


컴파일러마다 다르지만, 이는 차이가 있는 경우가있음

TRUE비교랑 FALSE비교하는것이 완전히 다른 경우가있음.
어떤값과 비교하는것은 무조건 Compace임.

그런데 TRUE/FALSE중 비교하는 것 중 하나가 비트연산으로 커버되는 경우가있음.
비트연산은 Compare가 아니므로 훨씬빠름.

--------------------------------------------------------------------------

TLS메모리풀의 성능

TLS메모리풀은 아주 사소한것부터 영향이 가기때문에, 신경을 많이 써야함.
(new쪽에서 생성자 호출, TLS메모리풀에서는 생성자빼는건 사기임.)

코드단이 아닌 어셈블리 코드를 보고 코드를 수정해나가야 함.

일반 new/delete 와 TLS메모리풀이랑 비교해야 10배정도 나옴..
그냥 메모리풀 <-> TLS메모리풀이랑은 기껏해야 2배...

--------------------------------------------------------------------------

성능측정시 청크크기

200, 300, 500등으로 다양하게 해볼 것.
포트폴리오에 들억라 것이므로 신경써서 만들 것.

--------------------------------------------------------------------------

TLS메모리풀 성능이 서버에 미치는 영향

거의 체감되지않는다.
라이브러리를 만드는 입장에서 성능을 올리기위해 시도하고 있는 것이다.

실무에서도 이정도까지 신경쓰지않음.
우선은 코드를 보기쉽게 짜는것이 최우선이며, 성능까지 부가되면 좋음.

--------------------------------------------------------------------------

TLS메모리풀 도입 후 모니터링의 변화

확보된 개수(CapaCity), 실제 AllocCount.
낱개에 대한 사용량을 보고자한다면 내부에 멤벼변수를 두고 인터락해야함.

모니터링시 좀더 상세한 정보가 필요할때는 해야겠지만,
성능측정이나 실제사용시에는 불필요한 코드는 빼야할 것

--------------------------------------------------------------------------

메모리풀 예외처리 기능


서버에는 여러개의 메모리풀이 들어가고, 사용자가 PlayerPool에서 
할당받은 포인터를 MonsterPool에 Free()의 인자로 넣어버릴 수있다.

이처럼 Free()로 잘못된 포인터를 전달하는 경우,
바깥에서 한 실수이지만 바깥으로 알려는 줘야한다.

(에러를 방어야 로직이 정상적으로 돌게끔 하는것은 불가능함)


해당 Pool만의 기호를 박는것은 너무 번거로움.
자동으로 넣게끔하되 확인만 가능하면되므로 최대한 간단하게 하되,
성능을 최우선적으로 봐야함.

--------------------------------------------------------------------------

